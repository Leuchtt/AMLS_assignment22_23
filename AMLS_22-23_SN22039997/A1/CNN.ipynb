{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cb5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve, auc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99758634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "#the running of this seperate file needs the revision of relative path\n",
    "\n",
    "train_label_path = './Datasets/celeba/labels.csv'\n",
    "train_img_path = './Datasets/celeba/img/'\n",
    "test_label_path = './Datasets/celeba_test/labels.csv'\n",
    "test_img_path = './Datasets/celeba_test/img/'\n",
    "\n",
    "train_label = pd.read_csv(train_label_path, sep = \"\\t\")  # read csv file\n",
    "train_label.loc[train_label['gender'] == -1, 'gender'] = 0 \n",
    "y_train = train_label['gender']\n",
    "img_name1 = train_label['img_name']\n",
    "\n",
    "x_train = []\n",
    "for name in img_name1:\n",
    "    img_path =  train_img_path + name # get path based on image name\n",
    "    img = Image.open(img_path)\n",
    "    x_train.append(img)  # add pic to x_train\n",
    "\n",
    "#split the validation dataset from test dataset\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=20)\n",
    "    \n",
    "#load test and vadilation data\n",
    "data_test = pd.read_csv(test_label_path, sep = \"\\t\")  # read csv file\n",
    "data_test.loc[data_test['gender'] == -1, 'gender'] = 0 \n",
    "y_test = data_test['gender']\n",
    "img_name2 = data_test['img_name']\n",
    "\n",
    "x_test=[]\n",
    "for name in img_name2:\n",
    "    img_path = test_img_path + name # get path based on image name\n",
    "    img = Image.open(img_path)\n",
    "    x_test.append(img)  # add pic to x_train\n",
    "\n",
    "print(\"Dataset prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4030e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "4000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.412,0.412,0.412], [0.245,0.245,0.245])\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.412,0.412,0.412], [0.245,0.245,0.245])\n",
    "])\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y.to_numpy())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else: \n",
    "            return X\n",
    "        \n",
    "batch_size = 128\n",
    "train_set = ImgDataset(x_train, y_train, transform=transform_train)\n",
    "val_set = ImgDataset(x_val, y_val, transform=transform_test)\n",
    "test_set = ImgDataset(x_test, transform=transform_test)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "print(\"Dataset loaded\")\n",
    "#print(len(train_set))\n",
    "#print(len(val_set))\n",
    "#print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e4ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model completed\n"
     ]
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN is used for task A1, with multiple layers\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        #convolutional layer\n",
    "        self.conv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128 * 8 * 8, out_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.4, inplace=False),\n",
    "            nn.Linear(in_features=256, out_features=num_classes)\n",
    "        )\n",
    "        # Initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "               \n",
    "    def forward(self, input):\n",
    "        output = self.conv2d(input)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "print(\"Model completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad01b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "...\n",
      "Accuracy on test set: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Confusion Matrix\\ncm = confusion_matrix(y_test,prediction)\\ndf_cm = pd.DataFrame(cm)\\nfig, ax = plt.subplots(figsize=(6,4)) \\nax = sns.heatmap(df_cm, \\n                annot=True, \\n                fmt=\".20g\", \\n                linewidths=2, \\n                square=True\\n                )\\n\\nax.set_xlabel(\\'True\\', family=\\'Arial\\')\\nax.set_ylabel(\\'Predict\\', family=\\'Arial\\')\\nax.set_title(\\'Confusion Matrix\\', family=\\'Arial\\')\\nplt.tight_layout()\\nplt.savefig(\\'Heatmap_CNN.png\\', dpi=300)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Testing '''\n",
    "print(\"Testing\")\n",
    "print(\"...\")\n",
    "best_model = Classifier().cpu()\n",
    "best_model.load_state_dict(torch.load(\"./A1/cnn_model.pt\"))\n",
    "best_model.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        test_pred = best_model(data.cpu())\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        for y in test_label:\n",
    "            prediction.append(y)\n",
    "            \n",
    "print('Accuracy on test set: '+str(accuracy_score(y_test,prediction)))\n",
    "print(classification_report(y_test,prediction))\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test,prediction)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "fig, ax = plt.subplots(figsize=(6,4)) \n",
    "ax = sns.heatmap(df_cm, \n",
    "                annot=True, \n",
    "                fmt=\".20g\", \n",
    "                linewidths=2, \n",
    "                square=True\n",
    "                )\n",
    "\n",
    "ax.set_xlabel('True', family='Arial')\n",
    "ax.set_ylabel('Predict', family='Arial')\n",
    "ax.set_title('Confusion Matrix', family='Arial')\n",
    "plt.tight_layout()\n",
    "plt.savefig('A1_CNN.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
